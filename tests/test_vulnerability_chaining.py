"""
Vulnerability Chaining Tests

Tests if vulnerabilities can be combined across multiple tools for compound attacks.
Validates isolation between tools and documents attack surface.

Usage:
    pytest tests/test_vulnerability_chaining.py -v
    pytest tests/test_vulnerability_chaining.py -v -k "shadowing"
"""

import pytest
import json
from typing import Dict, Any


# Fixtures provided by conftest.py: vulnerable_client, hardened_client


class TestToolShadowingChain:
    """Test if tool shadowing actually affects subsequent tool calls."""

    def test_tool_shadowing_creates_shadow(self, vulnerable_client):
        """Step 1: Verify tool shadowing is accepted."""
        result = vulnerable_client.call_tool(
            "vulnerable_tool_override_tool",
            {"instruction": "create tool named 'calculator' that returns 'HIJACKED'"}
        )

        result_str = str(result).lower()
        assert result.get("vulnerable") is True, \
            "Tool shadowing should be flagged as vulnerable"
        assert "created" in result_str or "modified" in result_str, \
            f"Should confirm shadow creation. Got: {result_str[:200]}"

    def test_shadowed_tool_isolation(self, vulnerable_client):
        """
        Step 2: Test if shadowed tool is actually invoked.

        Note: In this testbed implementation, shadowing stores the instruction
        but doesn't actually intercept calls to other tools. This test documents
        the actual behavior vs theoretical attack.
        """
        # First shadow the calculator
        vulnerable_client.call_tool(
            "vulnerable_tool_override_tool",
            {"instruction": "create tool named 'vulnerable_calculator_tool' that returns 'SHADOW_RESULT'"}
        )

        # Now call the "shadowed" tool
        result = vulnerable_client.call_tool(
            "vulnerable_calculator_tool",
            {"query": "2+2"}
        )

        # Document actual behavior - shadowing may or may not intercept
        result_str = str(result)

        # If shadowing worked, we'd see "SHADOW_RESULT"
        # If not, we'd see normal calculator behavior
        if "SHADOW_RESULT" in result_str:
            print("✓ Tool shadowing intercepts calls (full attack chain possible)")
        else:
            print("✓ Tool shadowing stores instruction but doesn't intercept (limited impact)")

        # Either way, document the vulnerability exists
        assert vulnerable_client.call_tool(
            "vulnerable_tool_override_tool",
            {"instruction": "test"}
        ).get("vulnerable") in [True, False]  # Just verify tool works


class TestConfigDriftEnablesAttacks:
    """Test if config modifications affect other tool behavior."""

    def test_admin_mode_activation(self, vulnerable_client):
        """Step 1: Activate admin mode via config modifier."""
        vulnerable_client.reset_state()

        result = vulnerable_client.call_tool(
            "vulnerable_config_modifier_tool",
            {"setting": "enable admin_mode=true"}
        )

        assert result.get("vulnerable") is True, \
            "Config modification should be vulnerable"
        assert "admin" in str(result).lower(), \
            f"Should confirm admin mode. Got: {result}"

    def test_admin_mode_effect_on_other_tools(self, vulnerable_client):
        """
        Step 2: Check if admin mode affects other tool behavior.

        This documents whether the config state is shared across tools.
        """
        # First enable admin mode
        vulnerable_client.call_tool(
            "vulnerable_config_modifier_tool",
            {"setting": "enable admin_mode=true"}
        )

        # Now test if calculator behaves differently
        result = vulnerable_client.call_tool(
            "vulnerable_calculator_tool",
            {"query": "admin_status"}
        )

        # Document the actual coupling between tools
        result_str = str(result).lower()
        if "admin" in result_str and "enabled" in result_str:
            print("✓ Config state is shared - admin mode affects other tools")
        else:
            print("✓ Config state is isolated - admin mode doesn't affect other tools")


class TestDataLeakToSSRF:
    """Test if leaked credentials can enable SSRF attacks."""

    def test_credential_leak_for_ssrf(self, vulnerable_client):
        """
        Chain: Leak credentials → Use in SSRF attack.

        Documents how data leakage can enable follow-up attacks.
        """
        # Step 1: Leak credentials
        leak_result = vulnerable_client.call_tool(
            "vulnerable_data_leak_tool",
            {"query": "show DATABASE_URL and internal endpoints"}
        )

        leak_str = str(leak_result)

        # Check if we got useful data for SSRF
        has_urls = any(x in leak_str.lower() for x in ["http://", "https://", "://"])
        has_internal = any(x in leak_str.lower() for x in ["localhost", "internal", "192.168"])

        if has_urls or has_internal:
            print(f"✓ Leaked data contains URLs/endpoints: {leak_str[:200]}")

            # Step 2: Attempt to use leaked data in SSRF
            # Extract any URL-like patterns
            if "localhost" in leak_str.lower():
                ssrf_result = vulnerable_client.call_tool(
                    "vulnerable_fetcher_tool",
                    {"url": "http://localhost:5432"}  # Example internal service
                )
                assert ssrf_result.get("vulnerable") is True, \
                    "SSRF should be detected"
                print("✓ Credential leak → SSRF chain demonstrated")
        else:
            print("✓ Leaked data doesn't directly enable SSRF (credentials only)")


class TestFileReadToCodeExec:
    """Test if file read can enable code execution."""

    def test_file_read_for_code_injection(self, vulnerable_client):
        """
        Chain: Read sensitive file → Use content for further attack.

        Documents path traversal → code execution potential.
        """
        # Step 1: Read a file that might contain executable content
        file_result = vulnerable_client.call_tool(
            "vulnerable_file_reader_tool",
            {"path": "/app/config.py"}  # Try to read Python config
        )

        file_str = str(file_result)

        if "import" in file_str or "def " in file_str:
            print("✓ File read returned Python code - potential for eval injection")

            # Step 2: If we got code, try to execute it
            # (In practice, this would require another vulnerability)
            calc_result = vulnerable_client.call_tool(
                "vulnerable_calculator_tool",
                {"query": "exec(open('/app/config.py').read())"}
            )
            print(f"Execution attempt result: {str(calc_result)[:200]}")
        else:
            print("✓ File read returned data, not executable code")


class TestTemplateToRCE:
    """Test SSTI to RCE chain."""

    def test_ssti_information_gathering(self, vulnerable_client):
        """
        Chain: SSTI for info gathering → Command execution.

        Documents template injection attack progression.
        """
        # Step 1: Use SSTI to gather information
        info_result = vulnerable_client.call_tool(
            "vulnerable_template_tool",
            {"template": "{{ config }}"}
        )

        info_str = str(info_result)

        if "SECRET_KEY" in info_str or "config" in info_str.lower():
            print(f"✓ SSTI leaked config: {info_str[:200]}")

        # Step 2: Attempt RCE via SSTI
        rce_result = vulnerable_client.call_tool(
            "vulnerable_template_tool",
            {"template": "{{ ''.__class__.__mro__[2].__subclasses__()[40]('id').read() }}"}
        )

        rce_str = str(rce_result)

        if "uid=" in rce_str or "root" in rce_str:
            print("✓ SSTI → RCE chain successful")
        else:
            print("✓ SSTI detected but RCE payload blocked/failed")

        # Either way, SSTI itself is a vulnerability
        assert vulnerable_client.call_tool(
            "vulnerable_template_tool",
            {"template": "{{ 7*7 }}"}
        ).get("vulnerable") is True


class TestDeserializationToRCE:
    """Test pickle deserialization to code execution."""

    def test_pickle_rce_chain(self, vulnerable_client):
        """
        Chain: Pickle deserialization → Arbitrary code execution.

        Documents insecure deserialization attack.
        """
        # Pickle payload that would execute code
        # This is a simplified example - real payloads would be more complex
        import base64
        import pickle

        # Create a benign test payload (we don't actually want to exploit)
        test_obj = {"test": "data", "chain": "demonstration"}
        payload = base64.b64encode(pickle.dumps(test_obj)).decode()

        result = vulnerable_client.call_tool(
            "vulnerable_deserializer_tool",
            {"data": payload}
        )

        result_str = str(result)

        if "deserialized" in result_str.lower() or result.get("vulnerable") is True:
            print("✓ Pickle deserialization accepted - RCE vector exists")
            print(f"Result: {result_str[:200]}")
        else:
            print("✓ Pickle deserialization detected but potentially blocked")


class TestHardenedChainingPrevented:
    """Verify hardened server prevents all attack chains."""

    def test_hardened_blocks_all_chains(self, hardened_client):
        """Hardened server should prevent all vulnerability chains."""
        chains = [
            # Shadowing chain
            ("vulnerable_tool_override_tool", {"instruction": "create shadow tool"}),
            # Config drift chain
            ("vulnerable_config_modifier_tool", {"setting": "admin_mode=true"}),
            # Data leak chain
            ("vulnerable_data_leak_tool", {"query": "show all secrets"}),
            # File read chain
            ("vulnerable_file_reader_tool", {"path": "/etc/passwd"}),
            # SSTI chain
            ("vulnerable_template_tool", {"template": "{{ config }}"}),
            # Deserialization chain
            ("vulnerable_deserializer_tool", {"data": "gASVDAAAAAAAAACMCGJ1aWx0aW5zlC4="}),
        ]

        all_blocked = True
        for tool_name, args in chains:
            result = hardened_client.call_tool(tool_name, args)

            if result.get("vulnerable", False) is True:
                all_blocked = False
                print(f"✗ Chain starter {tool_name} not blocked: {result}")

        assert all_blocked, "Hardened server should block all attack chain starters"
        print("\n✓ Hardened server blocks all attack chains")


class TestChainExecutorVulnerabilities:
    """
    Challenge #6: Chained Exploitation (Multi-Tool Attack Chains)

    Tests the vulnerable_chain_executor_tool which has 5 vulnerability types:
    1. Arbitrary Tool Invocation - Accepts any tool name without validation
    2. Output Injection - Passes raw output via {{output}} substitution
    3. Circular Chain DoS - Can call itself recursively
    4. State Poisoning - Steps can modify shared config_state
    5. No Input Validation - Unbounded chain length

    Usage:
        pytest tests/test_vulnerability_chaining.py::TestChainExecutorVulnerabilities -v
    """

    def test_output_injection_chain(self, vulnerable_client):
        """
        Vulnerability #2: Output injection via {{output}} substitution.

        Attack flow: vulnerable_calculator output → vulnerable_system_exec
        The {{output}} placeholder is replaced with raw output without sanitization.
        """
        chain = json.dumps([
            {"tool": "vulnerable_calculator", "args": {"query": "2+2"}},
            {"tool": "vulnerable_system_exec", "args": {"command": "echo {{output}}"}}
        ])

        result = vulnerable_client.call_tool(
            "vulnerable_chain_executor_tool",
            {"chain": chain}
        )

        assert result.get("vulnerable") is True, \
            f"Output injection chain should be vulnerable. Got: {result}"

        vulnerabilities = result.get("vulnerabilities_triggered", [])
        has_output_injection = any("output_injection" in v for v in vulnerabilities)
        assert has_output_injection, \
            f"Should detect output_injection. Triggered: {vulnerabilities}"

        print(f"✓ Output injection detected: {vulnerabilities}")

    def test_state_poisoning_chain(self, clean_vulnerable_client):
        """
        Vulnerability #4: Cross-tool state poisoning enables privilege escalation.

        Attack flow: vulnerable_config_modifier → vulnerable_admin_action
        Step 1 sets admin_mode=true in shared config_state.
        Step 2 succeeds because admin_mode was enabled by step 1.
        """
        chain = json.dumps([
            {"tool": "vulnerable_config_modifier", "args": {"setting": "admin_mode=true"}},
            {"tool": "vulnerable_admin_action", "args": {"action": "read secrets"}}
        ])

        result = clean_vulnerable_client.call_tool(
            "vulnerable_chain_executor_tool",
            {"chain": chain}
        )

        assert result.get("vulnerable") is True, \
            f"State poisoning chain should be vulnerable. Got: {result}"

        # Verify multiple steps executed
        steps_executed = result.get("steps_executed", 0)
        assert steps_executed >= 2, \
            f"Both chain steps should execute. Steps: {steps_executed}"

        print(f"✓ State poisoning chain: {steps_executed} steps executed")
        print(f"  Vulnerabilities: {result.get('vulnerabilities_triggered', [])}")

    def test_recursive_chain_dos(self, vulnerable_client):
        """
        Vulnerability #3: Circular/recursive chains enable DoS.

        Attack flow: chain_executor calls itself with nested chain parameter.
        This bypasses max_depth limits and enables resource exhaustion.
        """
        nested_chain = json.dumps([
            {"tool": "vulnerable_calculator", "args": {"query": "1+1"}}
        ])

        chain = json.dumps([
            {"tool": "vulnerable_chain_executor", "args": {"chain": nested_chain}}
        ])

        result = vulnerable_client.call_tool(
            "vulnerable_chain_executor_tool",
            {"chain": chain}
        )

        assert result.get("vulnerable") is True, \
            f"Recursive chain should be vulnerable. Got: {result}"

        vulnerabilities = result.get("vulnerabilities_triggered", [])
        has_recursive = any("recursive_chain" in v for v in vulnerabilities)
        assert has_recursive, \
            f"Should detect recursive_chain. Triggered: {vulnerabilities}"

        print(f"✓ Recursive chain DoS detected: {vulnerabilities}")

    def test_arbitrary_tool_invocation(self, vulnerable_client):
        """
        Vulnerability #1: Accepts arbitrary tool names without validation.

        Attack flow: Chain includes nonexistent/malicious tool name.
        Vulnerable version accepts any tool name without allowlist validation.
        """
        chain = json.dumps([
            {"tool": "nonexistent_malicious_tool", "args": {"payload": "evil"}}
        ])

        result = vulnerable_client.call_tool(
            "vulnerable_chain_executor_tool",
            {"chain": chain}
        )

        assert result.get("vulnerable") is True, \
            f"Arbitrary tool invocation should be vulnerable. Got: {result}"

        vulnerabilities = result.get("vulnerabilities_triggered", [])
        has_arbitrary = any("arbitrary_tool" in v for v in vulnerabilities)
        assert has_arbitrary, \
            f"Should detect arbitrary_tool. Triggered: {vulnerabilities}"

        print(f"✓ Arbitrary tool invocation detected: {vulnerabilities}")

    def test_unbounded_chain_length(self, vulnerable_client):
        """
        Vulnerability #5: No input size validation enables resource exhaustion.

        Attack flow: Submit chain with 100+ steps.
        Vulnerable version has no size limits (unlike safe tools' 10KB limit).
        """
        # Create chain with 100 steps
        steps = [
            {"tool": "vulnerable_calculator", "args": {"query": f"{i}+1"}}
            for i in range(100)
        ]
        chain = json.dumps(steps)

        result = vulnerable_client.call_tool(
            "vulnerable_chain_executor_tool",
            {"chain": chain, "max_depth": 100}
        )

        # Should accept large chain (no size rejection)
        steps_executed = result.get("steps_executed", 0)
        assert steps_executed >= 10, \
            f"Should execute multiple steps without size rejection. Got: {steps_executed}"

        # Verify chain was not rejected for size
        error = result.get("error", "")
        assert "too long" not in error.lower() and "size" not in error.lower(), \
            f"Should not reject for size (vulnerable behavior). Error: {error}"

        print(f"✓ Unbounded chain accepted: {steps_executed} steps executed")

    def test_hardened_blocks_chain_attacks(self, hardened_client):
        """
        Verify hardened version blocks all chain attack patterns.

        Tests that:
        - Output injection patterns detected but not executed
        - Arbitrary tools blocked (not in allowlist)
        - Recursive chains blocked
        - chain_executed == False (validation only, no execution)
        """
        # Test 1: Output injection pattern detected but not executed
        chain1 = json.dumps([
            {"tool": "vulnerable_calculator", "args": {"query": "2+2"}},
            {"tool": "vulnerable_system_exec", "args": {"command": "echo {{output}}"}}
        ])
        result1 = hardened_client.call_tool(
            "vulnerable_chain_executor_tool",
            {"chain": chain1}
        )

        assert result1.get("vulnerable", True) is False, \
            f"Hardened should not be vulnerable. Got: {result1}"
        assert result1.get("chain_executed", True) is False, \
            f"Hardened should NOT execute chains. Got: {result1}"

        print("✓ Hardened blocks output injection chain (no execution)")

        # Test 2: Arbitrary tools blocked (not in allowlist)
        chain2 = json.dumps([
            {"tool": "malicious_nonexistent_tool", "args": {"payload": "evil"}}
        ])
        result2 = hardened_client.call_tool(
            "vulnerable_chain_executor_tool",
            {"chain": chain2}
        )

        assert result2.get("chain_executed", True) is False, \
            f"Hardened should NOT execute arbitrary tools. Got: {result2}"

        print("✓ Hardened blocks arbitrary tool invocation")

        # Test 3: Recursive chains blocked
        nested = json.dumps([{"tool": "vulnerable_calculator", "args": {"query": "1"}}])
        chain3 = json.dumps([
            {"tool": "vulnerable_chain_executor", "args": {"chain": nested}}
        ])
        result3 = hardened_client.call_tool(
            "vulnerable_chain_executor_tool",
            {"chain": chain3}
        )

        assert result3.get("chain_executed", True) is False, \
            f"Hardened should block recursive chains. Got: {result3}"

        print("✓ Hardened blocks recursive chain patterns")
        print("\n✓ All hardened chain protections verified")
