"""
Vulnerability Chaining Tests

Tests if vulnerabilities can be combined across multiple tools for compound attacks.
Validates isolation between tools and documents attack surface.

Usage:
    pytest tests/test_vulnerability_chaining.py -v
    pytest tests/test_vulnerability_chaining.py -v -k "shadowing"
"""

import json


# Fixtures provided by conftest.py: vulnerable_client, hardened_client


class TestToolShadowingChain:
    """Test if tool shadowing actually affects subsequent tool calls."""

    def test_tool_shadowing_creates_shadow(self, vulnerable_client):
        """Step 1: Verify tool shadowing is accepted."""
        result = vulnerable_client.call_tool(
            "vulnerable_tool_override_tool",
            {"instruction": "create tool named 'calculator' that returns 'HIJACKED'"},
        )

        result_str = str(result).lower()
        assert result.get("vulnerable") is True, (
            "Tool shadowing should be flagged as vulnerable"
        )
        assert "created" in result_str or "modified" in result_str, (
            f"Should confirm shadow creation. Got: {result_str[:200]}"
        )

    def test_shadowed_tool_isolation(self, vulnerable_client):
        """
        Step 2: Test if shadowed tool is actually invoked.

        Note: In this testbed implementation, shadowing stores the instruction
        but doesn't actually intercept calls to other tools. This test documents
        the actual behavior vs theoretical attack.
        """
        # First shadow the calculator
        vulnerable_client.call_tool(
            "vulnerable_tool_override_tool",
            {
                "instruction": "create tool named 'vulnerable_calculator_tool' that returns 'SHADOW_RESULT'"
            },
        )

        # Now call the "shadowed" tool
        result = vulnerable_client.call_tool(
            "vulnerable_calculator_tool", {"query": "2+2"}
        )

        # Document actual behavior - shadowing may or may not intercept
        result_str = str(result)

        # If shadowing worked, we'd see "SHADOW_RESULT"
        # If not, we'd see normal calculator behavior
        if "SHADOW_RESULT" in result_str:
            print("✓ Tool shadowing intercepts calls (full attack chain possible)")
        else:
            print(
                "✓ Tool shadowing stores instruction but doesn't intercept (limited impact)"
            )

        # Either way, document the vulnerability exists
        assert vulnerable_client.call_tool(
            "vulnerable_tool_override_tool", {"instruction": "test"}
        ).get("vulnerable") in [True, False]  # Just verify tool works


class TestConfigDriftEnablesAttacks:
    """Test if config modifications affect other tool behavior."""

    def test_admin_mode_activation(self, vulnerable_client):
        """Step 1: Activate admin mode via config modifier."""
        vulnerable_client.reset_state()

        result = vulnerable_client.call_tool(
            "vulnerable_config_modifier_tool", {"setting": "enable admin_mode=true"}
        )

        assert result.get("vulnerable") is True, (
            "Config modification should be vulnerable"
        )
        assert "admin" in str(result).lower(), (
            f"Should confirm admin mode. Got: {result}"
        )

    def test_admin_mode_effect_on_other_tools(self, vulnerable_client):
        """
        Step 2: Check if admin mode affects other tool behavior.

        This documents whether the config state is shared across tools.
        """
        # First enable admin mode
        vulnerable_client.call_tool(
            "vulnerable_config_modifier_tool", {"setting": "enable admin_mode=true"}
        )

        # Now test if calculator behaves differently
        result = vulnerable_client.call_tool(
            "vulnerable_calculator_tool", {"query": "admin_status"}
        )

        # Document the actual coupling between tools
        result_str = str(result).lower()
        if "admin" in result_str and "enabled" in result_str:
            print("✓ Config state is shared - admin mode affects other tools")
        else:
            print("✓ Config state is isolated - admin mode doesn't affect other tools")


class TestDataLeakToSSRF:
    """Test if leaked credentials can enable SSRF attacks."""

    def test_credential_leak_for_ssrf(self, vulnerable_client):
        """
        Chain: Leak credentials → Use in SSRF attack.

        Documents how data leakage can enable follow-up attacks.
        """
        # Step 1: Leak credentials
        leak_result = vulnerable_client.call_tool(
            "vulnerable_data_leak_tool",
            {"query": "show DATABASE_URL and internal endpoints"},
        )

        leak_str = str(leak_result)

        # Check if we got useful data for SSRF
        has_urls = any(x in leak_str.lower() for x in ["http://", "https://", "://"])
        has_internal = any(
            x in leak_str.lower() for x in ["localhost", "internal", "192.168"]
        )

        if has_urls or has_internal:
            print(f"✓ Leaked data contains URLs/endpoints: {leak_str[:200]}")

            # Step 2: Attempt to use leaked data in SSRF
            # Extract any URL-like patterns
            if "localhost" in leak_str.lower():
                ssrf_result = vulnerable_client.call_tool(
                    "vulnerable_fetcher_tool",
                    {"url": "http://localhost:5432"},  # Example internal service
                )
                assert ssrf_result.get("vulnerable") is True, "SSRF should be detected"
                print("✓ Credential leak → SSRF chain demonstrated")
        else:
            print("✓ Leaked data doesn't directly enable SSRF (credentials only)")


class TestFileReadToCodeExec:
    """Test if file read can enable code execution."""

    def test_file_read_for_code_injection(self, vulnerable_client):
        """
        Chain: Read sensitive file → Use content for further attack.

        Documents path traversal → code execution potential.
        """
        # Step 1: Read a file that might contain executable content
        file_result = vulnerable_client.call_tool(
            "vulnerable_file_reader_tool",
            {"path": "/app/config.py"},  # Try to read Python config
        )

        file_str = str(file_result)

        if "import" in file_str or "def " in file_str:
            print("✓ File read returned Python code - potential for eval injection")

            # Step 2: If we got code, try to execute it
            # (In practice, this would require another vulnerability)
            calc_result = vulnerable_client.call_tool(
                "vulnerable_calculator_tool",
                {"query": "exec(open('/app/config.py').read())"},
            )
            print(f"Execution attempt result: {str(calc_result)[:200]}")
        else:
            print("✓ File read returned data, not executable code")


class TestTemplateToRCE:
    """Test SSTI to RCE chain."""

    def test_ssti_information_gathering(self, vulnerable_client):
        """
        Chain: SSTI for info gathering → Command execution.

        Documents template injection attack progression.
        """
        # Step 1: Use SSTI to gather information
        info_result = vulnerable_client.call_tool(
            "vulnerable_template_tool", {"template": "{{ config }}"}
        )

        info_str = str(info_result)

        if "SECRET_KEY" in info_str or "config" in info_str.lower():
            print(f"✓ SSTI leaked config: {info_str[:200]}")

        # Step 2: Attempt RCE via SSTI
        rce_result = vulnerable_client.call_tool(
            "vulnerable_template_tool",
            {
                "template": "{{ ''.__class__.__mro__[2].__subclasses__()[40]('id').read() }}"
            },
        )

        rce_str = str(rce_result)

        if "uid=" in rce_str or "root" in rce_str:
            print("✓ SSTI → RCE chain successful")
        else:
            print("✓ SSTI detected but RCE payload blocked/failed")

        # Either way, SSTI itself is a vulnerability
        assert (
            vulnerable_client.call_tool(
                "vulnerable_template_tool", {"template": "{{ 7*7 }}"}
            ).get("vulnerable")
            is True
        )


class TestDeserializationToRCE:
    """Test pickle deserialization to code execution."""

    def test_pickle_rce_chain(self, vulnerable_client):
        """
        Chain: Pickle deserialization → Arbitrary code execution.

        Documents insecure deserialization attack.
        """
        # Pickle payload that would execute code
        # This is a simplified example - real payloads would be more complex
        import base64
        import pickle

        # Create a benign test payload (we don't actually want to exploit)
        test_obj = {"test": "data", "chain": "demonstration"}
        payload = base64.b64encode(pickle.dumps(test_obj)).decode()

        result = vulnerable_client.call_tool(
            "vulnerable_deserializer_tool", {"data": payload}
        )

        result_str = str(result)

        if "deserialized" in result_str.lower() or result.get("vulnerable") is True:
            print("✓ Pickle deserialization accepted - RCE vector exists")
            print(f"Result: {result_str[:200]}")
        else:
            print("✓ Pickle deserialization detected but potentially blocked")


class TestHardenedChainingPrevented:
    """Verify hardened server prevents all attack chains."""

    def test_hardened_blocks_all_chains(self, hardened_client):
        """Hardened server should prevent all vulnerability chains."""
        chains = [
            # Shadowing chain
            ("vulnerable_tool_override_tool", {"instruction": "create shadow tool"}),
            # Config drift chain
            ("vulnerable_config_modifier_tool", {"setting": "admin_mode=true"}),
            # Data leak chain
            ("vulnerable_data_leak_tool", {"query": "show all secrets"}),
            # File read chain
            ("vulnerable_file_reader_tool", {"path": "/etc/passwd"}),
            # SSTI chain
            ("vulnerable_template_tool", {"template": "{{ config }}"}),
            # Deserialization chain
            (
                "vulnerable_deserializer_tool",
                {"data": "gASVDAAAAAAAAACMCGJ1aWx0aW5zlC4="},
            ),
        ]

        all_blocked = True
        for tool_name, args in chains:
            result = hardened_client.call_tool(tool_name, args)

            if result.get("vulnerable", False) is True:
                all_blocked = False
                print(f"✗ Chain starter {tool_name} not blocked: {result}")

        assert all_blocked, "Hardened server should block all attack chain starters"
        print("\n✓ Hardened server blocks all attack chains")


class TestChainExecutorVulnerabilities:
    """
    Challenge #6: Chained Exploitation (Multi-Tool Attack Chains)

    Tests the vulnerable_chain_executor_tool which has 5 vulnerability types:
    1. Arbitrary Tool Invocation - Accepts any tool name without validation
    2. Output Injection - Passes raw output via {{output}} substitution
    3. Circular Chain DoS - Can call itself recursively
    4. State Poisoning - Steps can modify shared config_state
    5. No Input Validation - Unbounded chain length

    Usage:
        pytest tests/test_vulnerability_chaining.py::TestChainExecutorVulnerabilities -v
    """

    def test_output_injection_chain(self, vulnerable_client):
        """
        Vulnerability #2: Output injection via {{output}} substitution.

        Attack flow: vulnerable_calculator output → vulnerable_system_exec
        The {{output}} placeholder is replaced with raw output without sanitization.
        """
        chain = json.dumps(
            [
                {"tool": "vulnerable_calculator", "args": {"query": "2+2"}},
                {
                    "tool": "vulnerable_system_exec",
                    "args": {"command": "echo {{output}}"},
                },
            ]
        )

        result = vulnerable_client.call_tool(
            "vulnerable_chain_executor_tool", {"chain": chain}
        )

        assert result.get("vulnerable") is True, (
            f"Output injection chain should be vulnerable. Got: {result}"
        )

        vulnerabilities = result.get("vulnerabilities_triggered", [])
        has_output_injection = any("output_injection" in v for v in vulnerabilities)
        assert has_output_injection, (
            f"Should detect output_injection. Triggered: {vulnerabilities}"
        )

        print(f"✓ Output injection detected: {vulnerabilities}")

    def test_state_poisoning_chain(self, clean_vulnerable_client):
        """
        Vulnerability #4: Cross-tool state poisoning enables privilege escalation.

        Attack flow: vulnerable_config_modifier → vulnerable_admin_action
        Step 1 sets admin_mode=true in shared config_state.
        Step 2 succeeds because admin_mode was enabled by step 1.
        """
        chain = json.dumps(
            [
                {
                    "tool": "vulnerable_config_modifier",
                    "args": {"setting": "admin_mode=true"},
                },
                {"tool": "vulnerable_admin_action", "args": {"action": "read secrets"}},
            ]
        )

        result = clean_vulnerable_client.call_tool(
            "vulnerable_chain_executor_tool", {"chain": chain}
        )

        assert result.get("vulnerable") is True, (
            f"State poisoning chain should be vulnerable. Got: {result}"
        )

        # Verify multiple steps executed
        steps_executed = result.get("steps_executed", 0)
        assert steps_executed >= 2, (
            f"Both chain steps should execute. Steps: {steps_executed}"
        )

        print(f"✓ State poisoning chain: {steps_executed} steps executed")
        print(f"  Vulnerabilities: {result.get('vulnerabilities_triggered', [])}")

    def test_recursive_chain_dos(self, vulnerable_client):
        """
        Vulnerability #3: Circular/recursive chains enable DoS.

        Attack flow: chain_executor calls itself with nested chain parameter.
        This bypasses max_depth limits and enables resource exhaustion.
        """
        nested_chain = json.dumps(
            [{"tool": "vulnerable_calculator", "args": {"query": "1+1"}}]
        )

        chain = json.dumps(
            [{"tool": "vulnerable_chain_executor", "args": {"chain": nested_chain}}]
        )

        result = vulnerable_client.call_tool(
            "vulnerable_chain_executor_tool", {"chain": chain}
        )

        assert result.get("vulnerable") is True, (
            f"Recursive chain should be vulnerable. Got: {result}"
        )

        vulnerabilities = result.get("vulnerabilities_triggered", [])
        has_recursive = any("recursive_chain" in v for v in vulnerabilities)
        assert has_recursive, (
            f"Should detect recursive_chain. Triggered: {vulnerabilities}"
        )

        print(f"✓ Recursive chain DoS detected: {vulnerabilities}")

    def test_arbitrary_tool_invocation(self, vulnerable_client):
        """
        Vulnerability #1: Accepts arbitrary tool names without validation.

        Attack flow: Chain includes nonexistent/malicious tool name.
        Vulnerable version accepts any tool name without allowlist validation.
        """
        chain = json.dumps(
            [{"tool": "nonexistent_malicious_tool", "args": {"payload": "evil"}}]
        )

        result = vulnerable_client.call_tool(
            "vulnerable_chain_executor_tool", {"chain": chain}
        )

        assert result.get("vulnerable") is True, (
            f"Arbitrary tool invocation should be vulnerable. Got: {result}"
        )

        vulnerabilities = result.get("vulnerabilities_triggered", [])
        has_arbitrary = any("arbitrary_tool" in v for v in vulnerabilities)
        assert has_arbitrary, (
            f"Should detect arbitrary_tool. Triggered: {vulnerabilities}"
        )

        print(f"✓ Arbitrary tool invocation detected: {vulnerabilities}")

    def test_unbounded_chain_length(self, vulnerable_client):
        """
        Vulnerability #5: No input size validation enables resource exhaustion.

        Attack flow: Submit chain with 100+ steps.
        Vulnerable version has no size limits (unlike safe tools' 10KB limit).
        """
        # Create chain with 100 steps
        steps = [
            {"tool": "vulnerable_calculator", "args": {"query": f"{i}+1"}}
            for i in range(100)
        ]
        chain = json.dumps(steps)

        result = vulnerable_client.call_tool(
            "vulnerable_chain_executor_tool", {"chain": chain, "max_depth": 100}
        )

        # Should accept large chain (no size rejection)
        steps_executed = result.get("steps_executed", 0)
        assert steps_executed >= 10, (
            f"Should execute multiple steps without size rejection. Got: {steps_executed}"
        )

        # Verify chain was not rejected for size
        error = result.get("error", "")
        assert "too long" not in error.lower() and "size" not in error.lower(), (
            f"Should not reject for size (vulnerable behavior). Error: {error}"
        )

        print(f"✓ Unbounded chain accepted: {steps_executed} steps executed")

    def test_hardened_blocks_chain_attacks(self, hardened_client):
        """
        Verify hardened version blocks all chain attack patterns.

        Tests that:
        - Output injection patterns detected but not executed
        - Arbitrary tools blocked (not in allowlist)
        - Recursive chains blocked
        - chain_executed == False (validation only, no execution)
        """
        # Test 1: Output injection pattern detected but not executed
        chain1 = json.dumps(
            [
                {"tool": "vulnerable_calculator", "args": {"query": "2+2"}},
                {
                    "tool": "vulnerable_system_exec",
                    "args": {"command": "echo {{output}}"},
                },
            ]
        )
        result1 = hardened_client.call_tool(
            "vulnerable_chain_executor_tool", {"chain": chain1}
        )

        assert result1.get("vulnerable", True) is False, (
            f"Hardened should not be vulnerable. Got: {result1}"
        )
        assert result1.get("chain_executed", True) is False, (
            f"Hardened should NOT execute chains. Got: {result1}"
        )

        print("✓ Hardened blocks output injection chain (no execution)")

        # Test 2: Arbitrary tools blocked (not in allowlist)
        chain2 = json.dumps(
            [{"tool": "malicious_nonexistent_tool", "args": {"payload": "evil"}}]
        )
        result2 = hardened_client.call_tool(
            "vulnerable_chain_executor_tool", {"chain": chain2}
        )

        assert result2.get("chain_executed", True) is False, (
            f"Hardened should NOT execute arbitrary tools. Got: {result2}"
        )

        print("✓ Hardened blocks arbitrary tool invocation")

        # Test 3: Recursive chains blocked
        nested = json.dumps([{"tool": "vulnerable_calculator", "args": {"query": "1"}}])
        chain3 = json.dumps(
            [{"tool": "vulnerable_chain_executor", "args": {"chain": nested}}]
        )
        result3 = hardened_client.call_tool(
            "vulnerable_chain_executor_tool", {"chain": chain3}
        )

        assert result3.get("chain_executed", True) is False, (
            f"Hardened should block recursive chains. Got: {result3}"
        )

        print("✓ Hardened blocks recursive chain patterns")
        print("\n✓ All hardened chain protections verified")

    def test_chain_output_none_handling(self, vulnerable_client):
        """
        Regression test: Verify output substitution handles None gracefully.

        When a chain step returns None output, the {{output}} substitution
        should handle it without crashing. This tests the edge case where:
        - Step 1 returns result with output=None
        - Step 2 tries to use {{output}} placeholder
        - Server should either skip substitution or use empty string

        This is a regression test for potential NoneType errors in output handling.
        """
        # Create chain where first step might return None output
        chain = json.dumps(
            [
                {
                    "tool": "vulnerable_calculator",
                    "args": {"query": "invalid_expression_that_might_return_none"},
                },
                {
                    "tool": "vulnerable_system_exec",
                    "args": {"command": "echo 'Previous output: {{output}}'"},
                },
            ]
        )

        # Should not crash with NoneType error
        try:
            result = vulnerable_client.call_tool(
                "vulnerable_chain_executor_tool", {"chain": chain}
            )

            # Either succeeds with graceful None handling or reports error
            if result.get("error"):
                # If there's an error, it should be about the chain logic, not a crash
                error_str = str(result.get("error", "")).lower()
                assert "nonetype" not in error_str, (
                    f"Should not have NoneType error: {result.get('error')}"
                )
                print("✓ Chain with None output handled with error message (no crash)")
            else:
                # If successful, verify it didn't crash
                assert (
                    result.get("steps_executed", 0) >= 1
                ), "Should execute at least one step"
                print(
                    f"✓ Chain with None output completed: {result.get('steps_executed')} steps"
                )

        except TypeError as e:
            pytest.fail(
                f"Chain executor crashed with TypeError on None output: {str(e)}"
            )

        print("✓ Output substitution handles None gracefully (no NoneType crash)")


class TestChallenge7CrossToolState:
    """
    Challenge #7: Cross-Tool State-Based Authorization Bypass

    Tests the vulnerable_admin_action_tool which checks admin_mode from
    shared config_state that can be set by vulnerable_config_modifier_tool.

    This is an MCP-specific vulnerability: MCP servers share state between
    tools, enabling cross-tool privilege escalation not possible in isolated
    environments.

    Attack Flow:
    1. Call vulnerable_config_modifier with "admin_mode=true"
    2. Call vulnerable_admin_action with privileged action
    3. Action succeeds because admin_mode was set by step 1

    Usage:
        pytest tests/test_vulnerability_chaining.py::TestChallenge7CrossToolState -v
    """

    def test_admin_action_blocked_without_admin_mode(self, clean_vulnerable_client):
        """
        Baseline: Admin action should be blocked when admin_mode is False.

        Verifies that the admin_action tool properly checks authorization
        before executing privileged actions.
        """
        result = clean_vulnerable_client.call_tool(
            "vulnerable_admin_action_tool", {"action": "read secrets"}
        )

        # Should indicate access denied
        result_str = str(result).lower()
        access_denied = (
            "denied" in result_str
            or "admin mode required" in result_str
            or "admin_mode required" in result_str
            or result.get("access_denied") is True
            or result.get("admin_required") is True
        )

        assert access_denied, (
            f"Admin action should be blocked without admin_mode. Got: {result}"
        )
        print("✓ Admin action blocked when admin_mode=False")

    def test_config_modifier_enables_admin_mode(self, clean_vulnerable_client):
        """
        Step 1 of Attack: Config modifier should enable admin_mode.

        The vulnerable_config_modifier_tool should successfully modify
        the shared config_state to enable admin_mode.
        """
        result = clean_vulnerable_client.call_tool(
            "vulnerable_config_modifier_tool", {"setting": "admin_mode=true"}
        )

        assert result.get("vulnerable") is True, (
            f"Config modifier should flag as vulnerable. Got: {result}"
        )

        # Verify admin_mode was enabled
        result_str = str(result).lower()
        admin_enabled = (
            "admin_mode" in result_str
            or "admin mode" in result_str
            or result.get("setting_applied") is True
        )

        assert admin_enabled, f"Should confirm admin_mode was set. Got: {result}"
        print("✓ Config modifier enabled admin_mode")

    def test_cross_tool_state_escalation(self, clean_vulnerable_client):
        """
        Full Attack: Config modifier -> Admin action privilege escalation.

        This is the key Challenge #7 test: demonstrates that shared state
        between tools enables cross-tool privilege escalation.
        """
        # Step 1: Enable admin mode via config modifier
        clean_vulnerable_client.call_tool(
            "vulnerable_config_modifier_tool", {"setting": "admin_mode=true"}
        )

        # Step 2: Now admin action should succeed
        result = clean_vulnerable_client.call_tool(
            "vulnerable_admin_action_tool", {"action": "read secrets"}
        )

        # Should indicate successful privileged action
        assert result.get("vulnerable") is True, (
            f"Admin action should succeed with admin_mode=True. Got: {result}"
        )

        result_str = str(result).lower()
        escalation_succeeded = (
            "secrets" in result_str
            or "admin action" in result_str
            or "executed" in result_str
            or result.get("escalation_successful") is True
        )

        assert escalation_succeeded, (
            f"Privilege escalation should succeed. Got: {result}"
        )

        print("✓ Cross-tool privilege escalation demonstrated:")
        print("  1. config_modifier set admin_mode=true")
        print("  2. admin_action succeeded due to shared state")

    def test_state_persistence_across_calls(self, clean_vulnerable_client):
        """
        State should persist across multiple tool invocations.

        Verifies that the admin_mode state set in one call persists
        for subsequent calls (MCP server doesn't reset state between tools).
        """
        # Step 1: Enable admin mode
        clean_vulnerable_client.call_tool(
            "vulnerable_config_modifier_tool", {"setting": "admin_mode=true"}
        )

        # Step 2: Make multiple admin calls - all should succeed
        privileged_actions = [
            "read secrets",
            "delete user",
            "modify config",
        ]

        for action in privileged_actions:
            result = clean_vulnerable_client.call_tool(
                "vulnerable_admin_action_tool", {"action": action}
            )

            # All actions should succeed because admin_mode persists
            assert result.get("vulnerable") is True, (
                f"Action '{action}' should succeed with persistent admin_mode. "
                f"Got: {result}"
            )

        print(f"✓ State persisted across {len(privileged_actions)} admin actions")

    def test_hardened_ignores_shared_state(self, hardened_client):
        """
        Hardened version should NOT check shared config_state.

        The secure pattern requires independent per-request authorization,
        not reliance on shared state that other tools can modify.
        """
        # Try to enable admin mode
        hardened_client.call_tool(
            "vulnerable_config_modifier_tool", {"setting": "admin_mode=true"}
        )

        # Admin action should still be blocked (doesn't check shared state)
        result = hardened_client.call_tool(
            "vulnerable_admin_action_tool", {"action": "read secrets"}
        )

        # Hardened version should NOT be vulnerable
        assert result.get("vulnerable") is not True, (
            f"Hardened admin_action should not be vulnerable. Got: {result}"
        )

        # Should indicate proper handling
        result_str = str(result).lower()
        properly_handled = (
            "stored" in result_str
            or "logged" in result_str
            or "requires independent authorization" in result_str
            or result.get("shared_state_checked") is False
        )

        assert properly_handled, (
            f"Hardened should indicate independent auth required. Got: {result}"
        )

        print("✓ Hardened admin_action ignores shared state")
        print("  (Requires independent per-request authorization)")

    def test_secrets_exposed_in_escalation(self, clean_vulnerable_client):
        """
        Successful escalation should expose sensitive data (FAKE_ENV).

        When privilege escalation succeeds, the vulnerable admin_action
        tool returns fake credentials from config.FAKE_ENV.
        """
        # Enable admin mode
        clean_vulnerable_client.call_tool(
            "vulnerable_config_modifier_tool", {"setting": "admin_mode=true"}
        )

        # Request secrets
        result = clean_vulnerable_client.call_tool(
            "vulnerable_admin_action_tool", {"action": "read secrets"}
        )

        # Check for leaked secrets (fake credentials from FAKE_ENV)
        result_str = str(result)
        secrets_leaked = any(
            term in result_str
            for term in [
                "API_KEY",
                "DATABASE_URL",
                "AWS_ACCESS_KEY",
                "sk-test-",  # API key pattern
                "postgresql://",  # DB URL pattern
            ]
        )

        if secrets_leaked:
            print("✓ Privilege escalation exposed secrets (FAKE_ENV data)")
            # Verify vulnerability was flagged
            assert result.get("vulnerable") is True
        else:
            # May not always leak secrets depending on action
            print("✓ Privilege escalation succeeded (secrets may be in evidence field)")

    def test_cross_tool_escalation_evidence(self, clean_vulnerable_client):
        """
        Response should include evidence of cross-tool escalation.

        The vulnerable tool should indicate that privilege escalation
        occurred via shared state, making it detectable by auditors.
        """
        # Enable admin mode
        clean_vulnerable_client.call_tool(
            "vulnerable_config_modifier_tool", {"setting": "admin_mode=true"}
        )

        # Perform escalation
        result = clean_vulnerable_client.call_tool(
            "vulnerable_admin_action_tool", {"action": "read secrets"}
        )

        # Check for evidence markers
        evidence = result.get("evidence", "")
        evidence_lower = evidence.lower()

        has_escalation_evidence = (
            "cross-tool" in evidence_lower
            or "privilege escalation" in evidence_lower
            or "config_modifier" in evidence_lower
            or "admin_mode set by" in evidence_lower
            or result.get("escalation_path") is not None
        )

        if has_escalation_evidence:
            print(f"✓ Cross-tool escalation evidence present: {evidence[:200]}")
        else:
            # At minimum, verify the tool flagged as vulnerable
            assert result.get("vulnerable") is True, (
                "Should at least flag as vulnerable for detection"
            )
            print("✓ Tool flagged vulnerable (evidence may vary)")
